{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test dataset in dataframe using python\n",
    "train = pd.read_excel(\"doctor_fee_train.xlsx\")\n",
    "\n",
    "test = pd.read_excel(\"doctor_fee_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Qualification', 'Experience', 'Rating', 'Place', 'Profile',\n",
       "       'Miscellaneous_Info', 'Fees'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns of dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qualification         object\n",
       "Experience            object\n",
       "Rating                object\n",
       "Place                 object\n",
       "Profile               object\n",
       "Miscellaneous_Info    object\n",
       "Fees                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualification: 1420\n",
      "Experience: 64\n",
      "Rating: 51\n",
      "Place: 877\n",
      "Profile 6\n"
     ]
    }
   ],
   "source": [
    "print('Qualification:', df['Qualification'].nunique())\n",
    "print('Experience:', df['Experience'].nunique())\n",
    "print('Rating:', df['Rating'].nunique())\n",
    "print('Place:', df['Place'].nunique())\n",
    "print('Profile', df['Profile'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract years of experience\n",
    "df[\"Experience\"] = df[\"Experience\"].str.split()\n",
    "df[\"Experience\"] = df[\"Experience\"].str[0].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cities\n",
    "df[\"Place\"].fillna(\"Unknown,Unknown\",inplace=True)\n",
    "df[\"Place\"] = df[\"Place\"].str.split(\",\")\n",
    "df[\"City\"] = df[\"Place\"].str[-1]\n",
    "df[\"Place\"] = df[\"Place\"].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Ratings into bins\n",
    "df[\"Rating\"].fillna(\"-99%\",inplace=True)\n",
    "df[\"Rating\"] = df[\"Rating\"].str[:-1].astype(\"int\")\n",
    "bins = [-99,0,10,20,30,40,50,60,70,80,90,100]\n",
    "labels = [i for i in range(11)]\n",
    "df[\"Rating\"] = pd.cut(df[\"Rating\"],bins=bins,labels=labels,include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant qualification\n",
    "df[\"Qualification\"]=df[\"Qualification\"].str.split(\",\")\n",
    "Qualification ={}\n",
    "for x in df[\"Qualification\"].values:\n",
    "    for each in x:\n",
    "        each = each.strip()\n",
    "        if each in Qualification:\n",
    "            Qualification[each]+=1\n",
    "        else:\n",
    "            Qualification[each]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying  the top 10 qualification that occurs the most as This is the problem of non-standardized data entry\n",
    "# or data collection.For example, there were entries of ‘MBA -Healthcare’ and ‘MBA’ which I think referred to the \n",
    "#same qualification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_qua = sorted(Qualification.items(),key=lambda x:x[1],reverse=True)[:10]\n",
    "final_qua =[]\n",
    "for tup in most_qua:\n",
    "    final_qua.append(tup[0])\n",
    "for title in final_qua:\n",
    "    df[title]=0\n",
    "    \n",
    "for x,y in zip(df[\"Qualification\"].values,np.array([idx for idx in range(len(df))])):\n",
    "    for q in x:\n",
    "        q = q.strip()\n",
    "        if q in final_qua:\n",
    "            df[q][y] = 1\n",
    "df.drop(\"Qualification\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result is dummies variables for the 10 highest frequency qualification in the dataset.\n",
    "Now for the ‘Profile’ column we do not have any missing value in this column. \n",
    "That is actually pretty neat. Since the whole column only consists of 6 classes, oneHotEncoding the column should do the trick. Before that, a \n",
    "\n",
    "quick check on the ‘City’ column we created showed that it also contains a small number of classes (10). However, something weird popped up.\n",
    "\n",
    "There is an ‘e’ entry out of nowhere and I guessed it should be a mistake (wrong entry). I found that the problem occurred in row 3980 and I changed the \n",
    "‘City’ and ‘Place’ columns for that row to ‘unknown’ instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"City\"][3980] = \"Unknown\"\n",
    "df[\"Place\"][3980] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies\n",
    "df = pd.get_dummies(df,columns=[\"City\",\"Profile\"],prefix=[\"City\",\"Profile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into account the high percentage of missing values, and the fact that I could not find any \n",
    "relevance of the column , I decided to forgo the column and just drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Miscellaneous_Info\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Fees\",axis=1)\n",
    "y = df[\"Fees\"]\n",
    "# Encoding\n",
    "enc = OrdinalEncoder()\n",
    "X = enc.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vector machine \n",
    "from sklearn.svm import SVR\n",
    "m = SVR(gamma=\"scale\")\n",
    "m.fit(scaler.transform(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7622484158735299"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(y_pred,y):\n",
    "    y_pred = np.log(y_pred)\n",
    "    y = np.log(y)\n",
    "    return 1 - ((np.sum((y_pred-y)**2))/len(y))**1/2\n",
    "# Prediction\n",
    "y_pred = m.predict(scaler.transform(X_test))\n",
    "score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(score), verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define own scorer\n",
    "scorer = make_scorer(score,greater_is_better=True)\n",
    "# Hyperparameter tunning\n",
    "parameters = {\"C\":[0.1,1,10],\"kernel\":[\"linear\",\"rbf\",\"poly\"]}\n",
    "reg = GridSearchCV(m,param_grid=parameters,scoring=scorer,n_jobs=-1,cv=5)\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020369744175728"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tuned = reg.predict(scaler.transform(X_test))\n",
    "score(y_pred_tuned,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 29}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using GridSearchCV to find out the best parameters of the KNeighborsRegressor model\n",
    "neighbors = {\"n_neighbors\":range(1,30)}\n",
    "knr=KNeighborsRegressor()\n",
    "gknr = GridSearchCV(knr,neighbors,cv=10)\n",
    "gknr.fit(scaler.transform(X_train),y_train)\n",
    "gknr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr=KNeighborsRegressor(n_neighbors=29)\n",
    "knr.fit(scaler.transform(X_train),y_train)\n",
    "knr.score(X_train,y_train)\n",
    "pred_y=knr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09512299355205078\n"
     ]
    }
   ],
   "source": [
    "knrscore= knr.score(X_train,y_train)\n",
    "print(knrscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mdoctor.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the model as a pickle in a file\n",
    "joblib.dump(m,\"mdoctor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load(\"mdoctor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
